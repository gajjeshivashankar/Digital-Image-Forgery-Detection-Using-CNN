{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices: tf.config.experimental.set_memory_growth(device, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, Activation, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm  # Importing tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#converts input image to ela applied image\n",
    "def convert_to_ela_image(path,quality):\n",
    "\n",
    "    original_image = Image.open(path).convert('RGB')\n",
    "\n",
    "    #resaving input image at the desired quality\n",
    "    resaved_file_name = 'resaved_image.jpg'     #predefined filename for resaved image\n",
    "    original_image.save(resaved_file_name,'JPEG',quality=quality)\n",
    "    resaved_image = Image.open(resaved_file_name)\n",
    "\n",
    "    #pixel difference between original and resaved image\n",
    "    ela_image = ImageChops.difference(original_image,resaved_image)\n",
    "    \n",
    "    #scaling factors are calculated from pixel extremas\n",
    "    extrema = ela_image.getextrema()\n",
    "    max_difference = max([pix[1] for pix in extrema])\n",
    "    if max_difference ==0:\n",
    "        max_difference = 1\n",
    "    scale = 350.0 / max_difference\n",
    "    \n",
    "    #enhancing elaimage to brighten the pixels\n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "\n",
    "    ela_image.save(\"ela_image.png\")\n",
    "    return ela_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image_path):\n",
    "    image_size = (128, 128)\n",
    "    return np.array(convert_to_ela_image(image_path, 90).resize(image_size)).flatten() / 255.0         #normalizing the array values obtained from input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # ELA converted images\n",
    "Y = [] # 0 for fake, 1 for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images : 100%|██████████| 7492/7492 [07:02<00:00, 17.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 7602\n",
      "Total labels: 7602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#adding authentic images\n",
    "\n",
    "path = 'CASIA2/Au'       \n",
    "for filename in tqdm(os.listdir(path),desc=\"Processing Images : \"):\n",
    "    if filename.endswith('jpg') or filename.endswith('png'):\n",
    "        full_path = os.path.join(path, filename)\n",
    "        X.append(prepare_image(full_path))        \n",
    "        Y.append(1)     # label for authentic images \n",
    "        \n",
    "print(f'Total images: {len(X)}\\nTotal labels: {len(Y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images : 100%|██████████| 5123/5123 [03:27<00:00, 24.71it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 9666\n",
      "Total labels: 9666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#adding forged images\n",
    "\n",
    "path = 'CASIA2/Tp'\n",
    "for filename in tqdm(os.listdir(path),desc=\"Processing Images : \"):\n",
    "    if filename.endswith('jpg') or filename.endswith('png'):\n",
    "        full_path = os.path.join(path, filename)\n",
    "        X.append(prepare_image(full_path))        \n",
    "        Y.append(0)     # label for forged images \n",
    "        \n",
    "print(f'Total images: {len(X)}\\nTotal labels: {len(Y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X = X.reshape(-1, 128, 128, 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning dataset for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 7345 , Training labels: 7345\n",
      "Validation images: 1837 , Validation labels: 1837\n",
      "Test images: 484 , Test labels: 484\n"
     ]
    }
   ],
   "source": [
    "# Training : Validation : Testing = 76 : 19 : 5\n",
    "X_temp, X_test, Y_temp, Y_test = train_test_split(X, Y, test_size = 0.05, random_state=5)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size = 0.2, random_state=5)\n",
    "X = X.reshape(-1,1,1,1)\n",
    "\n",
    "print(f'Training images: {len(X_train)} , Training labels: {len(Y_train)}')\n",
    "print(f'Validation images: {len(X_val)} , Validation labels: {len(Y_val)}')\n",
    "print(f'Test images: {len(X_test)} , Test labels: {len(Y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()  # Sequential Model\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (5, 5), padding = 'valid', activation = 'relu', input_shape = (128, 128, 3)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (5, 5), padding = 'valid', activation = 'relu'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (5, 5), padding = 'valid', activation = 'relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (5, 5), padding = 'valid', activation = 'relu'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (5, 5), padding = 'valid', activation = 'relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (5, 5), padding = 'valid', activation = 'relu'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', activation = 'relu'))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHIVA SHANKAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,232</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m4,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │       \u001b[38;5;34m102,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │       \u001b[38;5;34m102,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │       \u001b[38;5;34m102,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │       \u001b[38;5;34m102,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │       \u001b[38;5;34m102,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │        \u001b[38;5;34m51,232\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">568,449</span> (2.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m568,449\u001b[0m (2.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">568,449</span> (2.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m568,449\u001b[0m (2.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHIVA SHANKAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:34: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Optimizer\n",
    "init_lr = 1e-4   #learning rate for the optimizer\n",
    "optimizer = Adam(learning_rate = init_lr, decay = init_lr/epochs) \n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early Stopping\n",
    "early_stopping = EarlyStopping(monitor = 'val_accuracy',\n",
    "                               min_delta = 0,\n",
    "                               patience = 10,\n",
    "                               verbose = 0,\n",
    "                               mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 2s/step - accuracy: 0.7680 - loss: 0.4618 - val_accuracy: 0.8601 - val_loss: 0.2887\n",
      "Epoch 2/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 2s/step - accuracy: 0.8637 - loss: 0.2796 - val_accuracy: 0.8710 - val_loss: 0.2677\n",
      "Epoch 3/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 2s/step - accuracy: 0.8751 - loss: 0.2672 - val_accuracy: 0.8726 - val_loss: 0.2618\n",
      "Epoch 4/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 2s/step - accuracy: 0.8754 - loss: 0.2652 - val_accuracy: 0.8639 - val_loss: 0.2827\n",
      "Epoch 5/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 2s/step - accuracy: 0.8758 - loss: 0.2675 - val_accuracy: 0.8857 - val_loss: 0.2492\n",
      "Epoch 6/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 2s/step - accuracy: 0.8957 - loss: 0.2369 - val_accuracy: 0.8884 - val_loss: 0.2431\n",
      "Epoch 7/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 2s/step - accuracy: 0.9023 - loss: 0.2268 - val_accuracy: 0.9047 - val_loss: 0.2308\n",
      "Epoch 8/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 2s/step - accuracy: 0.8990 - loss: 0.2326 - val_accuracy: 0.9069 - val_loss: 0.2197\n",
      "Epoch 9/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 2s/step - accuracy: 0.9094 - loss: 0.2052 - val_accuracy: 0.9080 - val_loss: 0.2136\n",
      "Epoch 10/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 2s/step - accuracy: 0.9154 - loss: 0.1981 - val_accuracy: 0.9156 - val_loss: 0.1961\n",
      "Epoch 11/15\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 2s/step - accuracy: 0.9154 - loss: 0.2023 - val_accuracy: 0.9211 - val_loss: 0.1914\n",
      "Epoch 12/15\n",
      "\u001b[1m  8/230\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:16\u001b[0m 1s/step - accuracy: 0.9186 - loss: 0.2132"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,\n",
    "                 Y_train,\n",
    "                 batch_size = batch_size,\n",
    "                 epochs = epochs,\n",
    "                 validation_data = (X_val, Y_val),\n",
    "                 callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# get the dictionary containing each metric and the loss for each epoch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m history_dict \u001b[38;5;241m=\u001b[39m \u001b[43mhist\u001b[49m\u001b[38;5;241m.\u001b[39mhistory\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# save it as a json file\u001b[39;00m\n\u001b[0;32m      8\u001b[0m json\u001b[38;5;241m.\u001b[39mdump(history_dict, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "#save the model as a h5 file\n",
    "model.save('.h5') \n",
    "\n",
    "# get the dictionary containing each metric and the loss for each epoch\n",
    "history_dict = hist.history\n",
    "\n",
    "# save it as a json file\n",
    "json.dump(history_dict, open('', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the training and validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Figure 1\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory_dict\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(history_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,axes \u001b[38;5;241m=\u001b[39max[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      6\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m,fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history_dict' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMkAAAGyCAYAAAD+jZMxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjvklEQVR4nO3db2yd5Xn48ct28DGo2IRlsZPMNIOO0hZIaEI8QxFi8moJlC4vpnpQJVnEn9FmiMbaSkIgLqWNMwYoUjGNSGH0RVnSIkBVE5lRr1FF8RQ1iSU6EhANNFlVm2QddmZam9jP70V/mLlxIMfxsX1yfz7SeZGn9+NzuzeBS18fn1OSZVkWAAAAAJCw0qneAAAAAABMNZEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5OUdyX7yk5/E0qVLY+7cuVFSUhLPPffch96za9eu+PSnPx25XC4+9rGPxZNPPjmOrQIAUEjmPAAgZXlHsv7+/liwYEG0tbWd0vo33ngjbrjhhrjuuuuiq6srvvzlL8ctt9wSzz//fN6bBQCgcMx5AEDKSrIsy8Z9c0lJPPvss7Fs2bKTrrnrrrtix44d8fOf/3zk2t/8zd/E22+/He3t7eN9agAACsicBwCkZkahn6CzszMaGhpGXWtsbIwvf/nLJ71nYGAgBgYGRv48PDwcv/nNb+KP/uiPoqSkpFBbBQDOIFmWxbFjx2Lu3LlRWuptWAvBnAcATIVCzXkFj2Td3d1RXV096lp1dXX09fXFb3/72zj77LNPuKe1tTXuu+++Qm8NAEjA4cOH40/+5E+mehtnJHMeADCVJnrOK3gkG49169ZFc3PzyJ97e3vjggsuiMOHD0dlZeUU7gwAKBZ9fX1RW1sb55577lRvhf/DnAcAnK5CzXkFj2Q1NTXR09Mz6lpPT09UVlaO+dPFiIhcLhe5XO6E65WVlYYnACAvfoWvcMx5AMBUmug5r+Bv0FFfXx8dHR2jrr3wwgtRX19f6KcGAKCAzHkAwJkk70j2v//7v9HV1RVdXV0R8fuP/u7q6opDhw5FxO9fQr9ixYqR9bfffnscPHgwvvKVr8SBAwfi0Ucfje9973uxZs2aifkOAACYEOY8ACBleUeyn/3sZ3HFFVfEFVdcERERzc3NccUVV8SGDRsiIuLXv/71yCAVEfGnf/qnsWPHjnjhhRdiwYIF8dBDD8W3v/3taGxsnKBvAQCAiWDOAwBSVpJlWTbVm/gwfX19UVVVFb29vd6rAgA4JeaH4uCcAIB8FWp+KPh7kgEAAADAdCeSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQvHFFsra2tpg/f35UVFREXV1d7N69+wPXb968OT7+8Y/H2WefHbW1tbFmzZr43e9+N64NAwBQOOY8ACBVeUey7du3R3Nzc7S0tMTevXtjwYIF0djYGG+99daY65966qlYu3ZttLS0xP79++Pxxx+P7du3x913333amwcAYOKY8wCAlOUdyR5++OG49dZbY9WqVfHJT34ytmzZEuecc0488cQTY65/6aWX4uqrr46bbrop5s+fH5/97Gfjxhtv/NCfSgIAMLnMeQBAyvKKZIODg7Fnz55oaGh4/wuUlkZDQ0N0dnaOec9VV10Ve/bsGRmWDh48GDt37ozrr7/+pM8zMDAQfX19ox4AABSOOQ8ASN2MfBYfPXo0hoaGorq6etT16urqOHDgwJj33HTTTXH06NH4zGc+E1mWxfHjx+P222//wJfht7a2xn333ZfP1gAAOA3mPAAgdQX/dMtdu3bFxo0b49FHH429e/fGM888Ezt27Ij777//pPesW7cuent7Rx6HDx8u9DYBAMiTOQ8AOJPk9UqyWbNmRVlZWfT09Iy63tPTEzU1NWPec++998by5cvjlltuiYiIyy67LPr7++O2226L9evXR2npiZ0ul8tFLpfLZ2sAAJwGcx4AkLq8XklWXl4eixYtio6OjpFrw8PD0dHREfX19WPe884775wwIJWVlUVERJZl+e4XAIACMOcBAKnL65VkERHNzc2xcuXKWLx4cSxZsiQ2b94c/f39sWrVqoiIWLFiRcybNy9aW1sjImLp0qXx8MMPxxVXXBF1dXXx+uuvx7333htLly4dGaIAAJh65jwAIGV5R7KmpqY4cuRIbNiwIbq7u2PhwoXR3t4+8iavhw4dGvUTxXvuuSdKSkrinnvuiV/96lfxx3/8x7F06dL4xje+MXHfBQAAp82cBwCkrCQrgtfC9/X1RVVVVfT29kZlZeVUbwcAKALmh+LgnACAfBVqfij4p1sCAAAAwHQnkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkLxxRbK2traYP39+VFRURF1dXezevfsD17/99tuxevXqmDNnTuRyubj44otj586d49owAACFY84DAFI1I98btm/fHs3NzbFly5aoq6uLzZs3R2NjY7z66qsxe/bsE9YPDg7GX/7lX8bs2bPj6aefjnnz5sUvf/nLOO+88yZi/wAATBBzHgCQspIsy7J8bqirq4srr7wyHnnkkYiIGB4ejtra2rjjjjti7dq1J6zfsmVL/PM//3McOHAgzjrrrHFtsq+vL6qqqqK3tzcqKyvH9TUAgLSYH/JnzgMAikGh5oe8ft1ycHAw9uzZEw0NDe9/gdLSaGhoiM7OzjHv+cEPfhD19fWxevXqqK6ujksvvTQ2btwYQ0NDJ32egYGB6OvrG/UAAKBwzHkAQOryimRHjx6NoaGhqK6uHnW9uro6uru7x7zn4MGD8fTTT8fQ0FDs3Lkz7r333njooYfi61//+kmfp7W1NaqqqkYetbW1+WwTAIA8mfMAgNQV/NMth4eHY/bs2fHYY4/FokWLoqmpKdavXx9btmw56T3r1q2L3t7ekcfhw4cLvU0AAPJkzgMAziR5vXH/rFmzoqysLHp6ekZd7+npiZqamjHvmTNnTpx11llRVlY2cu0Tn/hEdHd3x+DgYJSXl59wTy6Xi1wul8/WAAA4DeY8ACB1eb2SrLy8PBYtWhQdHR0j14aHh6OjoyPq6+vHvOfqq6+O119/PYaHh0euvfbaazFnzpwxBycAACafOQ8ASF3ev27Z3NwcW7duje985zuxf//++OIXvxj9/f2xatWqiIhYsWJFrFu3bmT9F7/4xfjNb34Td955Z7z22muxY8eO2LhxY6xevXrivgsAAE6bOQ8ASFlev24ZEdHU1BRHjhyJDRs2RHd3dyxcuDDa29tH3uT10KFDUVr6fnurra2N559/PtasWROXX355zJs3L+6888646667Ju67AADgtJnzAICUlWRZlk31Jj5MX19fVFVVRW9vb1RWVk71dgCAImB+KA7OCQDIV6Hmh4J/uiUAAAAATHciGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRtXJGtra4v58+dHRUVF1NXVxe7du0/pvm3btkVJSUksW7ZsPE8LAECBmfMAgFTlHcm2b98ezc3N0dLSEnv37o0FCxZEY2NjvPXWWx9435tvvhn/8A//ENdcc824NwsAQOGY8wCAlOUdyR5++OG49dZbY9WqVfHJT34ytmzZEuecc0488cQTJ71naGgovvCFL8R9990XF1544WltGACAwjDnAQApyyuSDQ4Oxp49e6KhoeH9L1BaGg0NDdHZ2XnS+772ta/F7Nmz4+abbz6l5xkYGIi+vr5RDwAACsecBwCkLq9IdvTo0RgaGorq6upR16urq6O7u3vMe1588cV4/PHHY+vWraf8PK2trVFVVTXyqK2tzWebAADkyZwHAKSuoJ9ueezYsVi+fHls3bo1Zs2adcr3rVu3Lnp7e0cehw8fLuAuAQDIlzkPADjTzMhn8axZs6KsrCx6enpGXe/p6YmampoT1v/iF7+IN998M5YuXTpybXh4+PdPPGNGvPrqq3HRRRedcF8ul4tcLpfP1gAAOA3mPAAgdXm9kqy8vDwWLVoUHR0dI9eGh4ejo6Mj6uvrT1h/ySWXxMsvvxxdXV0jj8997nNx3XXXRVdXl5fXAwBME+Y8ACB1eb2SLCKiubk5Vq5cGYsXL44lS5bE5s2bo7+/P1atWhUREStWrIh58+ZFa2trVFRUxKWXXjrq/vPOOy8i4oTrAABMLXMeAJCyvCNZU1NTHDlyJDZs2BDd3d2xcOHCaG9vH3mT10OHDkVpaUHf6gwAgAIw5wEAKSvJsiyb6k18mL6+vqiqqore3t6orKyc6u0AAEXA/FAcnBMAkK9CzQ9+FAgAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSN65I1tbWFvPnz4+Kioqoq6uL3bt3n3Tt1q1b45prromZM2fGzJkzo6Gh4QPXAwAwdcx5AECq8o5k27dvj+bm5mhpaYm9e/fGggULorGxMd56660x1+/atStuvPHG+PGPfxydnZ1RW1sbn/3sZ+NXv/rVaW8eAICJY84DAFJWkmVZls8NdXV1ceWVV8YjjzwSERHDw8NRW1sbd9xxR6xdu/ZD7x8aGoqZM2fGI488EitWrDil5+zr64uqqqro7e2NysrKfLYLACTK/JA/cx4AUAwKNT/k9UqywcHB2LNnTzQ0NLz/BUpLo6GhITo7O0/pa7zzzjvx7rvvxvnnn3/SNQMDA9HX1zfqAQBA4ZjzAIDU5RXJjh49GkNDQ1FdXT3qenV1dXR3d5/S17jrrrti7ty5owawP9Ta2hpVVVUjj9ra2ny2CQBAnsx5AEDqJvXTLTdt2hTbtm2LZ599NioqKk66bt26ddHb2zvyOHz48CTuEgCAfJnzAIBiNyOfxbNmzYqysrLo6ekZdb2npydqamo+8N4HH3wwNm3aFD/60Y/i8ssv/8C1uVwucrlcPlsDAOA0mPMAgNTl9Uqy8vLyWLRoUXR0dIxcGx4ejo6Ojqivrz/pfQ888EDcf//90d7eHosXLx7/bgEAKAhzHgCQurxeSRYR0dzcHCtXrozFixfHkiVLYvPmzdHf3x+rVq2KiIgVK1bEvHnzorW1NSIi/umf/ik2bNgQTz31VMyfP3/kPS0+8pGPxEc+8pEJ/FYAADgd5jwAIGV5R7KmpqY4cuRIbNiwIbq7u2PhwoXR3t4+8iavhw4ditLS91+g9q1vfSsGBwfjr//6r0d9nZaWlvjqV796ersHAGDCmPMAgJSVZFmWTfUmPkxfX19UVVVFb29vVFZWTvV2AIAiYH4oDs4JAMhXoeaHSf10SwAAAACYjkQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSN65I1tbWFvPnz4+Kioqoq6uL3bt3f+D673//+3HJJZdERUVFXHbZZbFz585xbRYAgMIy5wEAqco7km3fvj2am5ujpaUl9u7dGwsWLIjGxsZ46623xlz/0ksvxY033hg333xz7Nu3L5YtWxbLli2Ln//856e9eQAAJo45DwBIWUmWZVk+N9TV1cWVV14ZjzzySEREDA8PR21tbdxxxx2xdu3aE9Y3NTVFf39//PCHPxy59ud//uexcOHC2LJlyyk9Z19fX1RVVUVvb29UVlbms10AIFHmh/yZ8wCAYlCo+WFGPosHBwdjz549sW7dupFrpaWl0dDQEJ2dnWPe09nZGc3NzaOuNTY2xnPPPXfS5xkYGIiBgYGRP/f29kbE7/9PAAA4Fe/NDXn+PDBZ5jwAoFgUas7LK5IdPXo0hoaGorq6etT16urqOHDgwJj3dHd3j7m+u7v7pM/T2toa99133wnXa2tr89kuAED893//d1RVVU31NqY9cx4AUGwmes7LK5JNlnXr1o36qeTbb78dH/3oR+PQoUOG3Gmqr68vamtr4/Dhw35VYhpzTsXBOU1/zqg49Pb2xgUXXBDnn3/+VG+F/8OcV3z8O684OKfi4JyKg3Oa/go15+UVyWbNmhVlZWXR09Mz6npPT0/U1NSMeU9NTU1e6yMicrlc5HK5E65XVVX5B3Saq6ysdEZFwDkVB+c0/Tmj4lBaOq4P806OOY8P4995xcE5FQfnVByc0/Q30XNeXl+tvLw8Fi1aFB0dHSPXhoeHo6OjI+rr68e8p76+ftT6iIgXXnjhpOsBAJh85jwAIHV5/7plc3NzrFy5MhYvXhxLliyJzZs3R39/f6xatSoiIlasWBHz5s2L1tbWiIi4884749prr42HHnoobrjhhti2bVv87Gc/i8cee2xivxMAAE6LOQ8ASFnekaypqSmOHDkSGzZsiO7u7li4cGG0t7ePvGnroUOHRr3c7aqrroqnnnoq7rnnnrj77rvjz/7sz+K5556LSy+99JSfM5fLRUtLy5gvzWd6cEbFwTkVB+c0/Tmj4uCc8mfOYyzOqDg4p+LgnIqDc5r+CnVGJZnPRQcAAAAgcd7JFgAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyZs2kaytrS3mz58fFRUVUVdXF7t37/7A9d///vfjkksuiYqKirjsssti586dk7TTdOVzRlu3bo1rrrkmZs6cGTNnzoyGhoYPPVMmRr5/l96zbdu2KCkpiWXLlhV2g0RE/uf09ttvx+rVq2POnDmRy+Xi4osv9u+9Asv3jDZv3hwf//jH4+yzz47a2tpYs2ZN/O53v5uk3abpJz/5SSxdujTmzp0bJSUl8dxzz33oPbt27YpPf/rTkcvl4mMf+1g8+eSTBd8n5rxiYM4rDua84mDOm/7MedPflM152TSwbdu2rLy8PHviiSey//zP/8xuvfXW7Lzzzst6enrGXP/Tn/40Kysryx544IHslVdeye65557srLPOyl5++eVJ3nk68j2jm266KWtra8v27duX7d+/P/vbv/3brKqqKvuv//qvSd55WvI9p/e88cYb2bx587Jrrrkm+6u/+qvJ2WzC8j2ngYGBbPHixdn111+fvfjii9kbb7yR7dq1K+vq6prknacj3zP67ne/m+Vyuey73/1u9sYbb2TPP/98NmfOnGzNmjWTvPO07Ny5M1u/fn32zDPPZBGRPfvssx+4/uDBg9k555yTNTc3Z6+88kr2zW9+MysrK8va29snZ8OJMudNf+a84mDOKw7mvOnPnFccpmrOmxaRbMmSJdnq1atH/jw0NJTNnTs3a21tHXP95z//+eyGG24Yda2uri77u7/7u4LuM2X5ntEfOn78eHbuuedm3/nOdwq1RbLxndPx48ezq666Kvv2t7+drVy50vA0CfI9p29961vZhRdemA0ODk7WFpOX7xmtXr06+4u/+ItR15qbm7Orr766oPvkfacyPH3lK1/JPvWpT4261tTUlDU2NhZwZ5jzpj9zXnEw5xUHc970Z84rPpM55035r1sODg7Gnj17oqGhYeRaaWlpNDQ0RGdn55j3dHZ2jlofEdHY2HjS9Zye8ZzRH3rnnXfi3XffjfPPP79Q20zeeM/pa1/7WsyePTtuvvnmydhm8sZzTj/4wQ+ivr4+Vq9eHdXV1XHppZfGxo0bY2hoaLK2nZTxnNFVV10Ve/bsGXmp/sGDB2Pnzp1x/fXXT8qeOTXmh8lnzpv+zHnFwZxXHMx5058578w1UfPDjInc1HgcPXo0hoaGorq6etT16urqOHDgwJj3dHd3j7m+u7u7YPtM2XjO6A/dddddMXfu3BP+oWXijOecXnzxxXj88cejq6trEnZIxPjO6eDBg/Hv//7v8YUvfCF27twZr7/+enzpS1+Kd999N1paWiZj20kZzxnddNNNcfTo0fjMZz4TWZbF8ePH4/bbb4+77757MrbMKTrZ/NDX1xe//e1v4+yzz56inZ25zHnTnzmvOJjzioM5b/oz5525JmrOm/JXknHm27RpU2zbti2effbZqKiomOrt8P8dO3Ysli9fHlu3bo1Zs2ZN9Xb4AMPDwzF79ux47LHHYtGiRdHU1BTr16+PLVu2TPXW+P927doVGzdujEcffTT27t0bzzzzTOzYsSPuv//+qd4aQEGZ86Ync17xMOdNf+a8tEz5K8lmzZoVZWVl0dPTM+p6T09P1NTUjHlPTU1NXus5PeM5o/c8+OCDsWnTpvjRj34Ul19+eSG3mbx8z+kXv/hFvPnmm7F06dKRa8PDwxERMWPGjHj11VfjoosuKuymEzSev09z5syJs846K8rKykaufeITn4ju7u4YHByM8vLygu45NeM5o3vvvTeWL18et9xyS0REXHbZZdHf3x+33XZbrF+/PkpL/UxqOjjZ/FBZWelVZAVizpv+zHnFwZxXHMx5058578w1UXPelJ9meXl5LFq0KDo6OkauDQ8PR0dHR9TX1495T319/aj1EREvvPDCSddzesZzRhERDzzwQNx///3R3t4eixcvnoytJi3fc7rkkkvi5Zdfjq6urpHH5z73ubjuuuuiq6sramtrJ3P7yRjP36err746Xn/99ZHhNiLitddeizlz5hicCmA8Z/TOO++cMCC9N+z+/r1GmQ7MD5PPnDf9mfOKgzmvOJjzpj9z3plrwuaHvN7mv0C2bduW5XK57Mknn8xeeeWV7LbbbsvOO++8rLu7O8uyLFu+fHm2du3akfU//elPsxkzZmQPPvhgtn///qylpcVHgxdYvme0adOmrLy8PHv66aezX//61yOPY8eOTdW3kIR8z+kP+dSjyZHvOR06dCg799xzs7//+7/PXn311eyHP/xhNnv27OzrX//6VH0LZ7x8z6ilpSU799xzs3/913/NDh48mP3bv/1bdtFFF2Wf//znp+pbSMKxY8eyffv2Zfv27csiInv44Yezffv2Zb/85S+zLMuytWvXZsuXLx9Z/95Hg//jP/5jtn///qytrW1cHw1Ofsx50585rziY84qDOW/6M+cVh6ma86ZFJMuyLPvmN7+ZXXDBBVl5eXm2ZMmS7D/+4z9G/rdrr702W7ly5aj13/ve97KLL744Ky8vzz71qU9lO3bsmOQdpyefM/roRz+aRcQJj5aWlsnfeGLy/bv0fxmeJk++5/TSSy9ldXV1WS6Xyy688MLsG9/4Rnb8+PFJ3nVa8jmjd999N/vqV7+aXXTRRVlFRUVWW1ubfelLX8r+53/+Z/I3npAf//jHY/635r2zWblyZXbttdeecM/ChQuz8vLy7MILL8z+5V/+ZdL3nSJz3vRnzisO5rziYM6b/sx5099UzXklWeb1gQAAAACkbcrfkwwAAAAApppIBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkLz/B7EkAI2yHataAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "#Figure 1\n",
    "ax[0].plot(history_dict['loss'], color='b', label = \"Training loss\")\n",
    "ax[0].plot(history_dict['val_loss'], color='r', label = \"Validation loss\",axes =ax[0])\n",
    "ax[0].set_xlabel('Epochs',fontsize=16)\n",
    "ax[0].set_ylabel('Loss',fontsize=16)\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "#Figure 2\n",
    "ax[1].plot(history_dict['accuracy'], color='b', label = \"Training accuracy\")\n",
    "ax[1].plot(history_dict['val_accuracy'], color='r',label = \"Validation accuracy\")\n",
    "ax[1].set_xlabel('Epochs',fontsize=16)\n",
    "ax[1].set_ylabel('Accuracy',fontsize=16)\n",
    "legend = ax[1].legend(loc='best', shadow=True)\n",
    "\n",
    "fig.suptitle('Metrics',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cf_matrix):\n",
    "  \n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()] #number of images in each classification block\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)] #percentage value of images in each block w.r.t total images\n",
    "\n",
    "    axes_labels=['Forged', 'Authentic']\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt='',cmap=\"flare\" , xticklabels=axes_labels, yticklabels=axes_labels)\n",
    "\n",
    "    plot_xlabel = plt.xlabel('Predicted labels', fontsize = 13)\n",
    "    plot_ylabel = plt.ylabel('True labels', fontsize = 13)\n",
    "    plot_title = plt.title('Confusion Matrix', fontsize= 10,fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_val\u001b[49m)               \u001b[38;5;66;03m# Predict the values from the validation dataset \u001b[39;00m\n\u001b[0;32m      2\u001b[0m Y_pred_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(Y_pred)           \u001b[38;5;66;03m# roundoff the sigmoid value\u001b[39;00m\n\u001b[0;32m      3\u001b[0m Y_true \u001b[38;5;241m=\u001b[39m Y_val                             \n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_val' is not defined"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_val)               # Predict the values from the validation dataset \n",
    "Y_pred_classes = np.round(Y_pred)           # roundoff the sigmoid value\n",
    "Y_true = Y_val                             \n",
    "\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)     # compute the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx)                         # plot the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(\u001b[43mY_true\u001b[49m, Y_pred_classes))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_true' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_true, Y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Forged', 'Authentic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m correct_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m#correctly predicted test images\u001b[39;00m\n\u001b[0;32m      3\u001b[0m total_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m   \u001b[38;5;66;03m#total test images\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index,image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(\u001b[43mX_test\u001b[49m,desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Images : \u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m      6\u001b[0m     image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      7\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Testing accuracy\n",
    "correct_test = 0 #correctly predicted test images\n",
    "total_test = 0   #total test images\n",
    "\n",
    "for index,image in enumerate(tqdm(X_test,desc=\"Processing Images : \")):\n",
    "    image = image.reshape(-1, 128, 128, 3)\n",
    "    y_pred = model.predict(image)\n",
    "    y_pred_class = np.round(y_pred)\n",
    "    total_test += 1\n",
    "    if y_pred_class == Y_test[index]: #if prediction is correct\n",
    "        correct_test += 1\n",
    "    \n",
    "print(f'Total test images: {total_test}\\nCorrectly predicted images: {correct_test}\\nAccuracy: {correct_test / total_test * 100.0} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\SHIVA SHANKAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:3251\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3251\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   3252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m test_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m    \u001b[38;5;66;03m# test image path\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_image \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_image_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m test_image \u001b[38;5;241m=\u001b[39m test_image\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_image)\n",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m, in \u001b[0;36mprepare_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_image\u001b[39m(image_path):\n\u001b[0;32m      2\u001b[0m     image_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mconvert_to_ela_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresize(image_size))\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m, in \u001b[0;36mconvert_to_ela_image\u001b[1;34m(path, quality)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_ela_image\u001b[39m(path,quality):\n\u001b[1;32m----> 4\u001b[0m     original_image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m#resaving input image at the desired quality\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     resaved_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresaved_image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m     \u001b[38;5;66;03m#predefined filename for resaved image\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SHIVA SHANKAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:3253\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3251\u001b[0m     fp\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   3252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation):\n\u001b[1;32m-> 3253\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m())\n\u001b[0;32m   3254\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3256\u001b[0m prefix \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m16\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "test_image_path = ''    # test image path\n",
    "test_image = prepare_image(test_image_path)\n",
    "test_image = test_image.reshape(-1, 128, 128, 3)\n",
    "\n",
    "y_pred = model.predict(test_image)\n",
    "y_pred_class = round(y_pred[0][0])\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,5)) \n",
    "\n",
    "#display original image\n",
    "original_image = plt.imread(test_image_path) \n",
    "ax[0].axis('off')\n",
    "ax[0].imshow(original_image)\n",
    "ax[0].set_title('Original Image')\n",
    "\n",
    "#display ELA applied image\n",
    "ax[1].axis('off')\n",
    "ax[1].imshow(convert_to_ela_image(test_image_path,90)) \n",
    "ax[1].set_title('ELA Image')\n",
    "\n",
    "print(f'Prediction: {class_names[y_pred_class]}')\n",
    "if y_pred<=0.5:\n",
    "    print(f'Confidence:  {(1-(y_pred[0][0])) * 100:0.2f}%')\n",
    "else:\n",
    "    print(f'Confidence: {(y_pred[0][0]) * 100:0.2f}%')\n",
    "print('--------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m test_folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m        \u001b[38;5;66;03m#dataset path\u001b[39;00m\n\u001b[0;32m      2\u001b[0m authentic,forged,total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_folder_path\u001b[49m\u001b[43m)\u001b[49m,desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Images : \u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpg\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      6\u001b[0m         test_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, filename)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: ''"
     ]
    }
   ],
   "source": [
    "test_folder_path = ''        #dataset path\n",
    "authentic,forged,total = 0,0,0\n",
    "\n",
    "for filename in tqdm(os.listdir(test_folder_path),desc=\"Processing Images : \"):\n",
    "    if filename.endswith('jpg') or filename.endswith('png'):\n",
    "        test_image_path = os.path.join(path, filename)\n",
    "        test_image = prepare_image(test_image_path)  \n",
    "        test_image.reshape(-1, 128, 128, 3)\n",
    "        y_pred = model.predict(image)\n",
    "        y_pred_class = np.round(y_pred)\n",
    "        total += 1\n",
    "        if y_pred_class == 0:\n",
    "            forged += 1\n",
    "        else:\n",
    "            authentic +=1\n",
    "\n",
    "print(f'Total images: {total}\\nAuthentic Images: {authentic}\\nForged Images: {forged}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
